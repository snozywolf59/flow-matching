{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9b6185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"VISIBLE_CUDA_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52b8a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from sklearn.datasets import make_circles\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a7da1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cpu\n",
      "None\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)  # Thông tin version CUDA mà PyTorch build cùng\n",
    "print(torch.backends.cudnn.enabled)\n",
    "# pip uninstall torch torchvision torchaudio -y\n",
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu129\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59042f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Flow(nn.Module):\n",
    "    def __init__(self, dim = 2, h = 256, v = 128):\n",
    "        super().__init__()\n",
    "        # vocab size\n",
    "        self.v = v\n",
    "        \n",
    "        # embed into \n",
    "        self.embed = nn.Embedding(v, h)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim * h + 1, h),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(h, h),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(h, dim * v)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_t: Tensor, t: Tensor):\n",
    "        return self.net(torch.cat((t[:, None], self.embed(x_t).flatten(1,2 )), -1)).\\\n",
    "            reshape(list(x_t.shape) + [self.v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de64a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 256\n",
    "vocab_size = 1280\n",
    "dim = 2\n",
    "\n",
    "flow = Flow(dim=dim, h=128, v=vocab_size).to(device)\n",
    "optim = torch.optim.Adam(flow.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36c9f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare source distribution\n",
    "\n",
    "\n",
    "\n",
    "factor=0.5\n",
    "noise=0.02\n",
    "\n",
    "# Generate circles dataset\n",
    "# X, y = make_circles(n_samples=640, factor=0.5, noise=0.05)\n",
    "# print(X)\n",
    "# print(y)\n",
    "# # Plot\n",
    "# plt.figure(figsize=(6,6))\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr', edgecolor='k', s=50)\n",
    "# plt.title(\"2D Visualization of make_circles Dataset\")\n",
    "# plt.xlabel(\"X1\")\n",
    "# plt.ylabel(\"X2\")\n",
    "# plt.axis('equal')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83a643ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 7.194931983947754\n",
      "Epoch 100: 2.8860220909118652\n",
      "Epoch 200: 2.6798343658447266\n",
      "Epoch 300: 2.6327335834503174\n",
      "Epoch 400: 2.1304094791412354\n",
      "Epoch 500: 2.478416681289673\n",
      "Epoch 600: 2.2733421325683594\n",
      "Epoch 700: 2.0717339515686035\n",
      "Epoch 800: 2.543961524963379\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m X_t = torch.where(torch.rand(batch_size, \u001b[32m2\u001b[39m) < t[:, \u001b[38;5;28;01mNone\u001b[39;00m], X_1, X_0)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# print(t)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m logits = \u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m loss = nn.functional.cross_entropy(logits.flatten(\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m), X_1.flatten(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)).mean()\n\u001b[32m     21\u001b[39m optim.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Dai hoc\\2526I\\dacn\\flow-matching\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Dai hoc\\2526I\\dacn\\flow-matching\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mFlow.forward\u001b[39m\u001b[34m(self, x_t, t)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_t: Tensor, t: Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.\\\n\u001b[32m     19\u001b[39m         reshape(\u001b[38;5;28mlist\u001b[39m(x_t.shape) + [\u001b[38;5;28mself\u001b[39m.v])\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Dai hoc\\2526I\\dacn\\flow-matching\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Dai hoc\\2526I\\dacn\\flow-matching\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Dai hoc\\2526I\\dacn\\flow-matching\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Dai hoc\\2526I\\dacn\\flow-matching\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Dai hoc\\2526I\\dacn\\flow-matching\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Dai hoc\\2526I\\dacn\\flow-matching\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epoch = 10000\n",
    "\n",
    "for _ in range(epoch):\n",
    "    X_1, __ = make_circles(n_samples=batch_size, factor=factor, noise=noise, random_state=0)\n",
    "    # print(X_1.shape)\n",
    "    # print(X_1)\n",
    "    X_1 = Tensor(X_1, device=device)\n",
    "    X_1 = X_1 * (vocab_size / 2) + vocab_size / 2\n",
    "    X_1 = torch.clamp(X_1, min=0.0, max=vocab_size - 1)\n",
    "    X_1 = torch.round(X_1).long()\n",
    "    # print(X_1.shape)\n",
    "    # print(X_1)\n",
    "    X_0 = torch.randint(low=0, high=vocab_size, size=(batch_size, 2))\n",
    "    # print(X_0)\n",
    "    t = torch.rand(batch_size)\n",
    "    X_t = torch.where(torch.rand(batch_size, 2) < t[:, None], X_1, X_0)\n",
    "    # print(t)\n",
    "    logits = flow(X_t, t)\n",
    "    loss = nn.functional.cross_entropy(logits.flatten(0,1), X_1.flatten(0, 1)).mean()\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    if _ % 100 == 0:\n",
    "        print(f'Epoch {_}: {loss.item()}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf2367",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create checkerboard dataset\u001b[39;00m\n\u001b[32m      5\u001b[39m n = \u001b[32m4\u001b[39m  \u001b[38;5;66;03m# number of squares along one axis\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m x = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m y = np.linspace(\u001b[32m0\u001b[39m, n, \u001b[32m1\u001b[39m / n)\n\u001b[32m      8\u001b[39m xx, yy = np.meshgrid(x, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Dai hoc\\2526I\\dacn\\flow-matching\\venv\\Lib\\site-packages\\numpy\\_core\\function_base.py:122\u001b[39m, in \u001b[36mlinspace\u001b[39m\u001b[34m(start, stop, num, endpoint, retstep, dtype, axis, device)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_linspace_dispatcher)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlinspace\u001b[39m(start, stop, num=\u001b[32m50\u001b[39m, endpoint=\u001b[38;5;28;01mTrue\u001b[39;00m, retstep=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     28\u001b[39m              axis=\u001b[32m0\u001b[39m, *, device=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     29\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    Return evenly spaced numbers over a specified interval.\u001b[39;00m\n\u001b[32m     31\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m \n\u001b[32m    121\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     num = \u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m num < \u001b[32m0\u001b[39m:\n\u001b[32m    124\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    125\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of samples, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, must be non-negative.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    126\u001b[39m         )\n",
      "\u001b[31mTypeError\u001b[39m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "sample_batch = 200\n",
    "x_t = torch.randint(0, high=vocab_size, size=(sample_batch, dim), device=device)\n",
    "t = 0.0\n",
    "results = [(x_t.clone(), t)]\n",
    "\n",
    "while t < 1.0 - 1e-3:\n",
    "    tt = torch.full((sample_batch,), t, device=device)\n",
    "    p1 = nn.functional.softmax(flow(x_t, tt), dim=-1)  # (batch, dim, vocab)\n",
    "\n",
    "    one_hot_x_t = nn.functional.one_hot(x_t, num_classes=vocab_size).float()  # (batch, dim, vocab)\n",
    "    h = min(0.1, 1.0 - t)\n",
    "    u = (p1 - one_hot_x_t) / max(1e-8, (1.0 - t))\n",
    "\n",
    "    probs = one_hot_x_t + h * u\n",
    "    probs = torch.clamp(probs, min=1e-9)\n",
    "    probs = probs / probs.sum(dim=-1, keepdim=True)\n",
    "\n",
    "    # sample new discrete tokens\n",
    "    # Categorical expects probs shape (..., num_categories) and returns indices\n",
    "    # flatten batch and dim to sample at once, then reshape\n",
    "    b, D, V = probs.shape\n",
    "    probs_flat = probs.view(b * D, V)\n",
    "    cat = torch.distributions.Categorical(probs=probs_flat)\n",
    "    samples_flat = cat.sample()  # (b*D,)\n",
    "    x_t = samples_flat.view(b, D)  # (b, D)\n",
    "\n",
    "    t = t + h\n",
    "    results.append((x_t.clone(), t))\n",
    "  \n",
    "print(len(results[0][0]))\n",
    "# for x_t, t in results:\n",
    "#   render_result(x_t)\n",
    "fig, axs = plt.subplots(1, len(results), figsize=(4*len(results), 4))\n",
    "for ax, (x_t, t) in zip(axs, results):\n",
    "    ax.scatter(x_t[:,0], x_t[:,1], c='blue', alpha=0.6)\n",
    "    ax.set_title(f\"t={t}\")\n",
    "    ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_images = []\n",
    "os.makedirs(\"tmp_frames\", exist_ok=True)\n",
    "\n",
    "for i, (x_t, t) in enumerate(results):\n",
    "    # Vẽ ảnh\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    x = x_t[:, 0].cpu().numpy()\n",
    "    y = x_t[:, 1].cpu().numpy()\n",
    "    ax.scatter(x, y, c='blue', alpha=0.6)\n",
    "    ax.set_title(f\"t={t}\")\n",
    "    ax.set_xlabel(\"x_1\")\n",
    "    ax.set_ylabel(\"x_2\")\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # Lưu từng frame\n",
    "    frame_path = f\"tmp_frames/frame_{i}.png\"\n",
    "    plt.savefig(frame_path)\n",
    "    gif_images.append(frame_path)\n",
    "    plt.close(fig)\n",
    "import imageio\n",
    "# Xuất GIF\n",
    "with imageio.get_writer('scatter_animation.gif', mode='I', duration=1) as writer:\n",
    "    for filename in gif_images:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "        os.remove(filename)\n",
    "\n",
    "print(\"GIF đã được lưu: scatter_animation.gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
